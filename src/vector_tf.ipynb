{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "078f64b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA device: NVIDIA GeForce RTX 4050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "import os\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75277376",
   "metadata": {},
   "source": [
    "## data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "483329c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading(filetype, folder = \"../data/pdf\"):\n",
    "    if(filetype == \"pdf\"):\n",
    "        loader = PyPDFLoader(folder)\n",
    "        \n",
    "    docs = loader.load()\n",
    "    \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee970b9",
   "metadata": {},
   "source": [
    "## Chuck Spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b646743e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Chuck_Spliting(docs):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap=200)\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "    # print(f\"split document into {len(splits)} part\")\n",
    "    # print(splits)\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd7ce59",
   "metadata": {},
   "source": [
    "## Embedding & retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03011b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Loading embedding model utility...\n",
      "INFO: Initializing HuggingFaceEmbeddings model: all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sukum\\Documents\\Project\\RAG_AI\\src\\embedded_utils.py:11: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "from embedded_utils import get_embedding_model\n",
    "embedding = get_embedding_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7252c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_fin_dict():\n",
    "    if not os.path.exists(\"../vectorDB/q-fin.topic\"):\n",
    "        os.makedirs(\"../vectorDB/q-fin.topic\")\n",
    "        # print(f\"Created directory: q-fin.topic\")\n",
    "    \n",
    "    q_fin_dict = {\n",
    "        'Risk Management': 'q-fin.RM',\n",
    "        'Computational Finance': 'q-fin.CP',\n",
    "        'Statistical Finance': 'q-fin.ST',\n",
    "        'Trading and Market Microstructure': 'q-fin.TR',\n",
    "        'Economics': 'q-fin.EC',\n",
    "        'General Finance': 'q-fin.GN',\n",
    "        'Mathematical Finance': 'q-fin.MF',\n",
    "        'Portfolio Management': 'q-fin.PM',\n",
    "        'Pricing of Securities': 'q-fin.PR'\n",
    "    }\n",
    "    key_list = [key for key in q_fin_dict]\n",
    "    vector_store = Chroma.from_texts(\n",
    "        texts=key_list,\n",
    "        embedding=embedding,\n",
    "        persist_directory=\"../vectorDB/q-fin.topic\"\n",
    "    )\n",
    "q_fin_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d235d31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PrinciplesofFinance-WEB', 'pdf']\n",
      "../vectorDB\\base/PrinciplesofFinance-WEB.pdf\n",
      "--------------------\n",
      "['Americanoptionsvaluationintime-dependentjump-diffusionmodelsviaintegralequationsandcharacteristicfunctions', 'pdf']\n",
      "../vectorDB\\q-fin.CP/Americanoptionsvaluationintime-dependentjump-diffusionmodelsviaintegralequationsandcharacteristicfunctions.pdf\n",
      "['EmpiricalModelsoftheTimeEvolutionofSPXOptionPrices', 'pdf']\n",
      "../vectorDB\\q-fin.CP/EmpiricalModelsoftheTimeEvolutionofSPXOptionPrices.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 12 0 (offset 0)\n",
      "Ignoring wrong pointing object 14 0 (offset 0)\n",
      "Ignoring wrong pointing object 16 0 (offset 0)\n",
      "Ignoring wrong pointing object 22 0 (offset 0)\n",
      "Ignoring wrong pointing object 24 0 (offset 0)\n",
      "Ignoring wrong pointing object 26 0 (offset 0)\n",
      "Ignoring wrong pointing object 28 0 (offset 0)\n",
      "Ignoring wrong pointing object 30 0 (offset 0)\n",
      "Ignoring wrong pointing object 75 0 (offset 0)\n",
      "Ignoring wrong pointing object 93 0 (offset 0)\n",
      "Ignoring wrong pointing object 95 0 (offset 0)\n",
      "Ignoring wrong pointing object 97 0 (offset 0)\n",
      "Ignoring wrong pointing object 99 0 (offset 0)\n",
      "Ignoring wrong pointing object 101 0 (offset 0)\n",
      "Ignoring wrong pointing object 176 0 (offset 0)\n",
      "Ignoring wrong pointing object 178 0 (offset 0)\n",
      "Ignoring wrong pointing object 180 0 (offset 0)\n",
      "Ignoring wrong pointing object 185 0 (offset 0)\n",
      "Ignoring wrong pointing object 187 0 (offset 0)\n",
      "Ignoring wrong pointing object 195 0 (offset 0)\n",
      "Ignoring wrong pointing object 197 0 (offset 0)\n",
      "Ignoring wrong pointing object 199 0 (offset 0)\n",
      "Ignoring wrong pointing object 207 0 (offset 0)\n",
      "Ignoring wrong pointing object 245 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "['AIistheStrategy']\n",
      "skip AIistheStrategy\n",
      "['AnAI-poweredToolforCentralBankBusinessLiaisons']\n",
      "skip AnAI-poweredToolforCentralBankBusinessLiaisons\n",
      "['Anewequilibrium']\n",
      "skip Anewequilibrium\n",
      "['ArtificialIntelligence,LeanStartupMethod,andProductInnovations', 'pdf']\n",
      "../vectorDB\\q-fin.EC/ArtificialIntelligence,LeanStartupMethod,andProductInnovations.pdf\n",
      "['Identifyingeconomicnarrativesinlargetextcorpora--AnintegratedapproachusingLargeLanguageModels', 'pdf']\n",
      "../vectorDB\\q-fin.EC/Identifyingeconomicnarrativesinlargetextcorpora--AnintegratedapproachusingLargeLanguageModels.pdf\n",
      "['OptimalRegulationandInvestmentIncentivesinFinancialNetworks', 'pdf']\n",
      "../vectorDB\\q-fin.EC/OptimalRegulationandInvestmentIncentivesinFinancialNetworks.pdf\n",
      "['SocialGroupBiasinAIFinance', 'pdf']\n",
      "../vectorDB\\q-fin.EC/SocialGroupBiasinAIFinance.pdf\n",
      "['SocialMediaCanReduceMisinformationWhenPublicScrutinyisHigh', 'pdf']\n",
      "../vectorDB\\q-fin.EC/SocialMediaCanReduceMisinformationWhenPublicScrutinyisHigh.pdf\n",
      "['TheEconomicValueofDepth', 'pdf']\n",
      "../vectorDB\\q-fin.EC/TheEconomicValueofDepth.pdf\n",
      "['TheTheoryofEconomicComplexity', 'pdf']\n",
      "../vectorDB\\q-fin.EC/TheTheoryofEconomicComplexity.pdf\n",
      "--------------------\n",
      "['PricingundertheBenchmarkApproach', 'pdf']\n",
      "../vectorDB\\q-fin.GN/PricingundertheBenchmarkApproach.pdf\n",
      "--------------------\n",
      "['Americanoptionsvaluationintime-dependentjump-diffusionmodelsviaintegralequationsandcharacteristicfunctions', 'pdf']\n",
      "../vectorDB\\q-fin.MF/Americanoptionsvaluationintime-dependentjump-diffusionmodelsviaintegralequationsandcharacteristicfunctions.pdf\n",
      "['PricingundertheBenchmarkApproach', 'pdf']\n",
      "../vectorDB\\q-fin.MF/PricingundertheBenchmarkApproach.pdf\n",
      "--------------------\n",
      "['Americanoptionsvaluationintime-dependentjump-diffusionmodelsviaintegralequationsandcharacteristicfunctions', 'pdf']\n",
      "../vectorDB\\q-fin.PR/Americanoptionsvaluationintime-dependentjump-diffusionmodelsviaintegralequationsandcharacteristicfunctions.pdf\n",
      "['EmpiricalModelsoftheTimeEvolutionofSPXOptionPrices', 'pdf']\n",
      "../vectorDB\\q-fin.PR/EmpiricalModelsoftheTimeEvolutionofSPXOptionPrices.pdf\n",
      "--------------------\n",
      "['ConditionalGenerativeModelingforEnhancedCreditRiskManagementinSupplyChainFinance', 'pdf']\n",
      "../vectorDB\\q-fin.RM/ConditionalGenerativeModelingforEnhancedCreditRiskManagementinSupplyChainFinance.pdf\n",
      "['DisasterRiskFinancingthroughTaxation']\n",
      "skip DisasterRiskFinancingthroughTaxation\n",
      "['OnDesignofRepresentativeDistributionallyRobustFormulationsforEvaluationofTailRiskMeasures', 'pdf']\n",
      "../vectorDB\\q-fin.RM/OnDesignofRepresentativeDistributionallyRobustFormulationsforEvaluationofTailRiskMeasures.pdf\n",
      "--------------------\n",
      "['PredictingStockMarketCrashwithBayesianGeneralisedParetoRegression', 'pdf']\n",
      "../vectorDB\\q-fin.ST/PredictingStockMarketCrashwithBayesianGeneralisedParetoRegression.pdf\n",
      "--------------------\n",
      "['CausalInterventionsinBondMulti-Dealer-to-ClientPlatforms', 'pdf']\n",
      "../vectorDB\\q-fin.TR/CausalInterventionsinBondMulti-Dealer-to-ClientPlatforms.pdf\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "dir = '../data'\n",
    "# print(f\"Recursively listing all items in: {os.path.abspath(dir)}\\n\")\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(dir):\n",
    "    if(len(dirnames) != 0): continue\n",
    "    docname = dirpath.split('/')[-1]\n",
    "    # print(f\"docname : \", docname)\n",
    "    des_doc = \"../vectorDB\" + dirpath[7:]\n",
    "\n",
    "    for name in filenames:\n",
    "        des_der = f\"{des_doc}/{name}\"\n",
    "\n",
    "        if not os.path.exists(des_der):\n",
    "            os.makedirs(des_der)\n",
    "        \n",
    "        try:\n",
    "            folder = os.path.join(dirpath,name)\n",
    "            split = name.split(\".\")\n",
    "            print(split)\n",
    "            filetype = split[1]\n",
    "            filename = split[0]\n",
    "            docs = data_loading(folder = folder, filetype=filetype)\n",
    "            splits = Chuck_Spliting(docs)\n",
    "            texts_from_splits = [doc.page_content for doc in splits]\n",
    "            metadatas_from_splits = [doc.metadata for doc in splits]\n",
    "            \n",
    "            # vector transform\n",
    "            print(des_der)\n",
    "            vector_store = Chroma.from_texts(\n",
    "                texts=texts_from_splits,\n",
    "                embedding=embedding,\n",
    "                metadatas=metadatas_from_splits,\n",
    "                persist_directory=des_der\n",
    "            )\n",
    "        except:\n",
    "            print(f\"skip {name}\")\n",
    "    print(\"-\" * 20)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
